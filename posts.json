[
    {
        "file": "posts/post1.md",
        "title": "Why We Think",
        "excerpt": "Special thanks to John Schulman for super valuable feedback. Test time compute and Chain-of-thought (CoT)...",
        "date": "May 1, 2025",
        "readingTime": "40 min",
        "author": "Lilian Weng",
        "tags": ["language-model", "reasoning", "math-heavy"]
    },
    {
        "file": "posts/post2.md",
        "title": "Reward Hacking in Reinforcement Learning",
        "excerpt": "Reward hacking occurs when a RL agent exploits flaws in the reward function without completing the intended task...",
        "date": "November 28, 2024",
        "readingTime": "37 min",
        "author": "Lilian Weng",
        "tags": ["language-model", "reasoning", "math-heavy"]
    },
    {
        "file": "posts/post3.md",
        "title": "Extrinsic Hallucinations in LLMs",
        "excerpt": "Hallucination in large language models refers to generating unfaithful or fabricated content...",
        "date": "September 12, 2024",
        "readingTime": "32 min",
        "author": "Lilian Weng",
        "tags": ["language-model", "reasoning", "math-heavy"]
    }
]